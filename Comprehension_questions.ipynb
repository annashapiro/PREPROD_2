{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0522e5d2-ad65-45b1-8239-5576c6bd74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import janitor as jn\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda8ab01-ec63-4522-b3b4-199c3b80bc45",
   "metadata": {},
   "source": [
    "# Evaluation of comprehension question responses during experiment (from PsychoPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df80541a-45a7-44de-a663-8e18cefed9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# This turns off all warnings but aiming specifically at the Chained Assignment warning, because to my best knowledge the code should still work under pandas 3.0\n",
    "# If it is not the case, remove this line of code to find out more"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108901ec-a393-4236-8425-5b5a30038280",
   "metadata": {},
   "source": [
    "## Function to recode cumulative button press responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af27f8f5-db54-4f07-9964-73ae64eff503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_diff(df, columns):\n",
    "\n",
    "    for column in columns:\n",
    "        # Prepare new column names\n",
    "        new_column_name = column.replace('button_', '').replace('numClicks', 'numClicksDiff')\n",
    "        # Initialize new column with zeros\n",
    "        df[new_column_name] = 0\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            if i == 0:\n",
    "                # Keep first value unchanged...\n",
    "                df[new_column_name].iloc[i] = df[column].iloc[i]\n",
    "            elif df[column].iloc[i] == 0:\n",
    "                # ... as well as any 0's - we want only differences if count of button presses increases\n",
    "                df[new_column_name].iloc[i] = df[column].iloc[i]\n",
    "            else:\n",
    "                # For all other values, calculate the difference to previous row\n",
    "                df[new_column_name].iloc[i] = df[column].iloc[i] - df[column].iloc[i-1]\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e68e9-cee4-408d-9bd8-49cb67c86665",
   "metadata": {},
   "source": [
    "## Single file analysis (Ana's preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "56f0bde6-b238-44cd-8be7-e9fed1142cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path - this should contain all files to be analyzed\n",
    "# Can be from multiple participants (4+ files), or from one, which will be 4 files (2 blocks x 2 sessions)\n",
    "# Output will be in 1:1 ratio (for each input file, one output file)\n",
    "\n",
    "inputdir = \"C:/Users/annas/OneDrive/Desktop/BCBL/Preprod_2 (Jupyter)/data/compquest\"\n",
    "\n",
    "# Create list of files\n",
    "all_filepaths = list(Path(inputdir).rglob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a1c1f80-1a07-412e-9519-2cae5c658691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\10026_1_French_TongueTapping_A1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\10026_1_Spanish_TongueTapping_A1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\10026_2_Spanish_SyllableProduction_B1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\10026_4_French_SyllableProduction_B1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\11903_1_Spanish_TongueTapping_A2.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\11903_2_Spanish_SyllableProduction_B2.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\4849_1_French_TongueTapping_A2.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\4849_2_French_SyllableProduction_B2.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\4849_3_Spanish_TongueTapping_A2.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\4849_4_Spanish_SyllableProduction_B2.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\4963_1_French_TongueTapping_B1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\4963_2_French_SyllableProduction_A1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\7797_1_Spanish_TongueTapping_B1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\7797_2_Spanish_SyllableProduction_A1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\cristina3_3_Spanish_TongueTapping_A1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\cristina4_4_Spanish_SyllableProduction_B1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\cristina_1_French_TongueTapping_A1.csv\n",
      "Processing file: C:\\Users\\annas\\OneDrive\\Desktop\\BCBL\\Preprod_2 (Jupyter)\\data\\compquest\\cristina_2_French_SyllableProduction_B1.csv\n"
     ]
    }
   ],
   "source": [
    "for filepath in all_filepaths:\n",
    "    # Read the Excel file\n",
    "    # Drop column with instructions as it will throw a tokenizing error with sep = comma\n",
    "    # i.e instructions contain a comma, so the reader will attempt to split the data in more columns than exist for the rest of data\n",
    "    df = pd.read_csv(filepath, usecols=lambda x: x != \"text_instructions\")\n",
    "\n",
    "    # Drop all NaN rows and practice trials\n",
    "    df = df[df['question'].apply(lambda x: pd.notna(x))]\n",
    "\n",
    "    # Only keep rows with comprehension questions\n",
    "    df = df[df['words'].isna()]\n",
    "\n",
    "    # Re-code button responses (change cumulative to regular binary)\n",
    "    df = custom_diff(df, ['button_v.numClicks', 'button_f.numClicks', 'button_idontknow.numClicks'])\n",
    "\n",
    "    # Re-code button response into one column\n",
    "    df['button_response'] = df.apply(lambda x: 'True' if (x['v.numClicksDiff'] == 1)\n",
    "                                      else 'False' if (x['f.numClicksDiff'] == 1)\n",
    "                                      else 'Idk', axis=1)\n",
    "\n",
    "    # Determine response\n",
    "    df['response'] = df.apply(lambda x: 'NaN' if (pd.isna(x['answer']))\n",
    "                                      else 'Correct' if (x['v.numClicksDiff'] == 1 and x['answer'] == True)\n",
    "                                      else 'Correct' if (x['f.numClicksDiff'] == 1 and x['answer'] == False)\n",
    "                                      else 'Incorrect', axis=1)\n",
    "\n",
    "    # Sanity check in case of an error, to know which file was last successfully processed\n",
    "    print(\"Processing file:\", filepath)\n",
    "    \n",
    "    # Select columns of interest\n",
    "    df = df.loc[:, ['Subject ID', 'Language', 'Block', 'List', 'item', 'question', 'answer', 'button_response', 'response']]\n",
    "    \n",
    "    # Get original file name\n",
    "    excel_file_name = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    \n",
    "    # Concatenate it with _compquest to name the output and save as Excel shet\n",
    "    df.to_excel(f'{excel_file_name}_compquest.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad569b5-fe9c-478c-8f8b-39866df329e2",
   "metadata": {},
   "source": [
    "## 'Mass' analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4c0a6-194c-49a1-a87f-8d7f0ce46912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path - this should contain all files to be analyzed\n",
    "# Can be from multiple participants (4+ files), or from one, which will be 4 files (2 blocks x 2 sessions)\n",
    "# Output will be 1 file\n",
    "inputdir = \"C:/Users/annas/OneDrive/Desktop/BCBL/Preprod_2 (Jupyter)/data/compquest\"\n",
    "\n",
    "# Create list of files\n",
    "all_filepaths = list(Path(inputdir).rglob(\"*.csv\"))\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b25d4e-f10b-4aab-a2d9-b40ab6555fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in all_filepaths:\n",
    "    # Read the Excel file\n",
    "    # Drop column with instructions as it will throw a tokenizing error with sep = comma\n",
    "    # i.e instructions contain a comma, so the reader will attempt to split the data in more columns than exist for the rest of data\n",
    "    df = pd.read_csv(filepath, usecols=lambda x: x != \"text_instructions\")\n",
    "\n",
    "    # Drop all NaN rows and practice trials\n",
    "    df = df[df['question'].apply(lambda x: pd.notna(x))]\n",
    "\n",
    "    # Only keep rows with comprehension questions\n",
    "    df = df[df['words'].isna()]\n",
    "\n",
    "    # Re-code button responses (change cumulative to regular binary)\n",
    "    df = custom_diff(df, ['button_v.numClicks', 'button_f.numClicks', 'button_idontknow.numClicks'])\n",
    "\n",
    "    # Re-code button response into one column\n",
    "    df['button_response'] = df.apply(lambda x: 'True' if (x['v.numClicksDiff'] == 1)\n",
    "                                      else 'False' if (x['f.numClicksDiff'] == 1)\n",
    "                                      else 'Idk', axis=1)\n",
    "\n",
    "    # Determine response\n",
    "    df['response'] = df.apply(lambda x: 'NaN' if (pd.isna(x['answer']))\n",
    "                                      else 'Correct' if (x['v.numClicksDiff'] == 1 and x['answer'] == True)\n",
    "                                      else 'Correct' if (x['f.numClicksDiff'] == 1 and x['answer'] == False)\n",
    "                                      else 'Incorrect', axis=1)\n",
    "\n",
    "\n",
    "    # Select columns of interest\n",
    "    df = df.loc[:, ['Subject ID', 'Language', 'Block', 'List', 'item', 'question', 'answer', 'button_response', 'response']]\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Combine all dataframes in the list into one dataframe\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Output\n",
    "# Name file according to the first cell in Subject ID column\n",
    "merged_df.to_excel(f'{merged_df.loc[merged_df.index[0], 'Subject ID']}_compquest.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fe9fad-e6a1-4316-86b8-1f65d49ce620",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e62e88-ae04-48f8-9ab8-780b51bf2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outtakes: extended ver. of function\n",
    "def custom_diff(df, columns):\n",
    "\n",
    "    for column in columns:\n",
    "        # Prepare new column names\n",
    "        new_column_name = column.replace('button_', '').replace('numClicks', 'numClicksDiff')\n",
    "        # Initialize new column with zeros\n",
    "        df[new_column_name] = 0\n",
    "\n",
    "        found_first_one = False  # Flag to identify the first occurrence of 1\n",
    "        for i in range(len(df)):\n",
    "            if df[column].iloc[i] == 1 and not found_first_one:\n",
    "                # Keep the first occurrence of 1 unchanged\n",
    "                df[new_column_name].iloc[i] = df[column].iloc[i]\n",
    "                found_first_one = True\n",
    "            elif found_first_one:\n",
    "                if df[column].iloc[i] == 0:\n",
    "                    # If the row contains 0, keep it as 0\n",
    "                    df[new_column_name].iloc[i] = 0\n",
    "                else:\n",
    "                    # Calculate the difference with the previous row\n",
    "                    df[new_column_name].iloc[i] = df[column].iloc[i] - df[column].iloc[i-1]\n",
    "            else:\n",
    "                # Before the first occurrence of 1, keep the values unchanged\n",
    "                df[new_column_name].iloc[i] = df[column].iloc[i]\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfcb51-f16c-45dc-a883-ba3733a0a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outtakes: practice trial manipulations\n",
    "\n",
    "    # Distinguish practice and experimental trials\n",
    "    df = df.case_when(\n",
    "        df['rp_sentence'].notna(), 'Practice', \n",
    "        df['sentence'].notna(), 'Experiment',\n",
    "        column_name = 'trial'\n",
    "    )\n",
    "\n",
    "    # Combine columns\n",
    "    df['question'] = df['rp_sentence_comprehensionq'].combine_first(df['question'])\n",
    "    df['words'] = df['rp_words'].combine_first(df['words'])\n",
    "    df['button_v.numClicks'] = df['button_rp_v.numClicks'].combine_first(df['button_v.numClicks'])\n",
    "    df['button_f.numClicks'] = df['button_rp_f.numClicks'].combine_first(df['button_f.numClicks'])\n",
    "    df['button_idk.numClicks'] = df['button_rp_idk.numClicks'].combine_first(df['button_idontknow.numClicks'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
